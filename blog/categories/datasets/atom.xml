<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Datasets | HBM Hackathon]]></title>
  <link href="http://ohbm-seattle.github.io/blog/categories/datasets/atom.xml" rel="self"/>
  <link href="http://ohbm-seattle.github.io/"/>
  <updated>2013-05-03T15:54:47-07:00</updated>
  <id>http://ohbm-seattle.github.io/</id>
  <author>
    <name><![CDATA[OHBM Organizing Committee]]></name>
    <email><![CDATA[hbm.hackathon@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Human Connectome Project Q1 Release: Now Cloud Accessible]]></title>
    <link href="http://ohbm-seattle.github.io/blog/2013/05/03/human-connectome-project-q1-release-now-cloud-accessible/"/>
    <updated>2013-05-03T13:00:00-07:00</updated>
    <id>http://ohbm-seattle.github.io/blog/2013/05/03/human-connectome-project-q1-release-now-cloud-accessible</id>
    <content type="html"><![CDATA[<p><img src="http://www.humanconnectome.org/img/header-bg.png" title="&#34;Human Connectom Project&#34;" alt="&#34;Human Connectom Project&#34;"></p>

<p>The <a href="http://www.humanconnectome.org/data/">first full quarterly HCP Data release</a> is now Cloud accessible for participants who have <a href="http://www.humanconnectome.org/data/data-use-terms/index.html">registered</a> and agreed to the <a href="http://www.humanconnectome.org/data/data-use-terms/open-access.html">Open Access Data Use Terms</a>.</p>

<!-- more -->


<p>HBM Hackathon participants will have the opportunity for high speed access to the first full quarterly HCP Data release via Amazon Web Services. All data available from the HCP Connectome-in-a-Box can now be downloaded directly from S3, Amazon’s Simple Storage Service.</p>

<h4>This post is organized into three sections:</h4>

<ol>
<li>Description of the HCP Q1 Release</li>
<li>Getting Authorized to Access the HCP Data</li>
<li>Accessing HCP Data on AWS</li>
</ol>


<h3>Description of the HCP Q1 Release</h3>

<p>The Q1 data release consists of multimodal MRI data collected from 68 healthy young adults who were scanned in the fall of 2012. These include all 12 subjects from our Initial Data Release. All 3T MRI scan data is included: Structural, Functional (resting state and task) and Diffusion. Behavioral data collected on all subjects is also included, with the exception of sensitive restricted-access data. Please see the <a href="http://www.humanconnectome.org/documentation/Q1/">Full Release Documentation</a> for further details.</p>

<h3>Getting Authorized to Access the HCP Data</h3>

<p>There are a few steps you will need to take to get authorization to access the HCP data hosted on AWS.</p>

<h4>You need to:</h4>

<ol>
<li>Complete the <strong><a href="http://www.humanconnectome.org/data/data-use-terms/index.html">HCP Registration</a></strong> and agree to the <strong><a href="http://www.humanconnectome.org/data/data-use-terms/open-access.html">HCP Open Access Data Use Terms</a></strong></li>
<li>Complete the <strong><a href="http://www.humanbrainmapping.org/hackathon">HBM Hackathon Registration</a></strong></li>
<li>Create an <strong><a href="http://aws.amazon.com/">Amazon Web Services Account</a></strong></li>
<li>Email <strong><a href="&#109;&#x61;&#105;&#108;&#116;&#111;&#58;&#x68;&#x62;&#109;&#46;&#104;&#97;&#99;&#x6b;&#x61;&#116;&#104;&#x6f;&#110;&#64;&#103;&#109;&#x61;&#x69;&#108;&#46;&#x63;&#x6f;&#x6d;">&#x68;&#98;&#109;&#x2e;&#104;&#97;&#x63;&#107;&#97;&#x74;&#104;&#111;&#x6e;&#x40;&#103;&#109;&#97;&#x69;&#108;&#46;&#x63;&#x6f;&#109;</a></strong> with your HCP and AWS email address(es)</li>
</ol>


<h4>A foreword from David van Essen:</h4>

<blockquote><p><strong>For distribution to all investigators interested in using HCP Connectome-in-a-Box data.</strong><br/>
</br>
<strong>IMPORTANT NOTICE to investigators wanting to use HCP datasets available on Connectome-in-a-Box hard drives.</strong><br/>
</br>
HCP’s Connectome-in-a-Box provides imaging data from the Open Access dataset. Before using any of these data for research, you and all other investigators using the data are required to <a href="http://www.humanconnectome.org/data/data-use-terms/index.html">register</a> and agree to the <a href="http://www.humanconnectome.org/data/data-use-terms/open-access.html">Open Access Data Use Terms</a>. <strong>This includes agreeing to comply with institutional rules and regulations</strong>.  This may mean that you need your research to be approved or declared exempt by a committee that oversees research on human subjects (e.g., your IRB or Ethics Committee).  The released HCP data are not considered de-identified, insofar as certain combinations of HCP Restricted Data (available through a separate process) might allow identification of individuals.  Different committees operate under different national, state and local laws and may interpret regulations differently, so it is important to ask about this. If needed and upon request, the HCP will provide a certificate stating that you have accepted the HCP Open Access Data Use Terms.<br/>
</br>
Sincerely,<br/>
David C. Van Essen (PI), for the WU-Minn HCP Consortium<br/>
May 1, 2013</p></blockquote>

<h3>Accessing HCP Data on AWS</h3>

<p>Amazon Web Services is hosting the HCP Q1 Data Release as part of its Public Data Sets on AWS program, which will enable HBM Hackathon participants to get rapid access to the HCP data. Since the data is hosted on S3 in an uncompressed format, participants can download data in parallel using tools like <a href="https://github.com/pcorliss/s3cmd-modification">s3cmd-modification</a>.</p>

<p>You can use tools like <a href="https://github.com/pcorliss/s3cmd-modification">s3cmd</a> to list the contents of a directory on S3, get individual files or sync full directories. You will also be able to download directly to your personal/work computer or to a machine on the EC2 Cloud like the <a href="https://aws.amazon.com/marketplace/pp/B00AW0MBLO">NITRC Computational Environment</a>.</p>

<h4>Getting Credentials</h4>

<p>Ready to start downloading? Make sure you've completed the <a href="http://www.humanconnectome.org/data/data-use-terms/index.html">HCP registration</a> and <a href="http://aws.amazon.com/">created an account with AWS</a>.</p>

<p>Next, send an email to <strong><a href="&#109;&#97;&#x69;&#108;&#116;&#x6f;&#58;&#x68;&#98;&#109;&#x2e;&#x68;&#97;&#x63;&#x6b;&#97;&#x74;&#104;&#111;&#110;&#x40;&#x67;&#109;&#x61;&#105;&#x6c;&#46;&#99;&#x6f;&#x6d;">&#104;&#x62;&#x6d;&#46;&#x68;&#x61;&#x63;&#x6b;&#97;&#x74;&#x68;&#x6f;&#110;&#x40;&#103;&#x6d;&#x61;&#105;&#x6c;&#46;&#99;&#111;&#x6d;</a></strong> with your HCP and AWS email address(es).</p>

<p>We will use your HCP and AWS email address(es) to:</p>

<ol>
<li>verify that you have agreed to the <a href="http://www.humanconnectome.org/data/data-use-terms/open-access.html">Open Access Data Use Agreement</a></li>
<li>grant you access to the HCP data on AWS.</li>
</ol>


<p>Once verified, you will receive an email confirming that you have access to the HCP data on AWS.</p>

<h4>Configuring your system</h4>

<p>To access the data you'll want to install <a href="https://github.com/pcorliss/s3cmd-modification">s3cmd-modification</a>, which will enable you to explore the <a href="http://humanconnectome.org/documentation/data-release/Q1_Release_Appendix_III.pdf">HCP Data Directory</a> on Amazon and will allow rapid parallel downloading (<a href="https://github.com/pcorliss/s3cmd-modification/blob/master/INSTALL">s3cmd-modification install instructions</a>).</p>

<p>After you install s3cmd, you need to configure it with your AWS public and secret keys, located in <a href="https://portal.aws.amazon.com/gp/aws/securityCredentials">AWS Security Credentials</a>.</p>

<pre><code>:~ s3cmd --configure
Enter new values or accept defaults in brackets with Enter.
Refer to user manual for detailed description of all options.

Access key and Secret key are your identifiers for Amazon S3
Access Key []: &lt;your-access-key&gt;
Secret Key []: &lt;your-secret-key&gt;
... 
</code></pre>

<p>Take s3cmd out for a test drive...</p>

<p>List subject directories:</p>

<pre><code>:~ s3cmd ls s3://hcp.aws.amazon.com/q1/

DIR   s3://hcp.aws.amazon.com/q1/100307/
DIR   s3://hcp.aws.amazon.com/q1/103515/
DIR   s3://hcp.aws.amazon.com/q1/111312/
...
DIR   s3://hcp.aws.amazon.com/q1/937160/
2013-04-17 06:57         0   s3://hcp.aws.amazon.com/q1/
</code></pre>

<p>Get a directory in parallel:</p>

<pre><code>:~ s3cmd --parallel --workers=16 get --recursive s3://hcp.aws.amazon.com/q1/100307/T1w T1w

File s3://hcp.aws.amazon.com/q1/100307/T1w/BiasField_acpc_dc.nii.gz started [2 of 52]
File s3://hcp.aws.amazon.com/q1/100307/T1w/Native/100307.L.MyelinMap.native.func.gii started [3 of 52]
...
File s3://hcp.aws.amazon.com/q1/100307/T1w/T2w_acpc_dc_restore.nii.gz saved as 'T1w/T1w/T2w_acpc_dc_restore.nii.gz' (67855816 bytes in 143.3 seconds, 462.31 kB/s)
File s3://hcp.aws.amazon.com/q1/100307/T1w/BiasField_acpc_dc.nii.gz saved as 'T1w/T1w/BiasField_acpc_dc.nii.gz' (65076318 bytes in 180.3 seconds, 352.50 kB/s)
</code></pre>

<p>If everything checks out, you are ready to get hacking!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[OpenfMRI Now an HBM Hackathon Resource]]></title>
    <link href="http://ohbm-seattle.github.io/blog/2013/04/22/openfmri-now-an-hbm-hackathon-resource/"/>
    <updated>2013-04-22T14:28:00-07:00</updated>
    <id>http://ohbm-seattle.github.io/blog/2013/04/22/openfmri-now-an-hbm-hackathon-resource</id>
    <content type="html"><![CDATA[<p><img src="https://openfmri.org/sites/all/themes/openfmri/logo.png" title="height=150 &#34;OpenfMRI&#34;" alt="height=150 &#34;OpenfMRI&#34;"></p>

<p>The <a href="http://openfmri.org">OpenfMRI</a> project provides raw and processed task fMRI datasets for use in re-analysis and mega-analysis that are now Cloud accessible.</p>

<!-- more -->


<h4>Background</h4>

<p>Currently the OpenfMRI database contains data from 18 studies (totaling 374 scanning sessions) across a wide range of different cognitive task domains, including: visual perception (object recognition, mirror reading), language processing (semantic judgments, rhyme judgments, pseudoword reading), working memory (tone counting, 1-back), cognitive control (stop signal, flanker, and Simon tasks), learning (category learning), decision making (gambling task, balloon analog risk task), memory encoding emotion regulation (reappraisal task), and social perception (false belief task).</p>

<p>More details about these datasets can be obtained from <a href="http://openfmri.org/data-sets">http://openfmri.org/data-sets</a>. The data will also be made available via AWS.</p>

<h4>Processing</h4>

<p>The data have been preprocessed and analyzed through a full group-level fMRI analysis, using an automated FSL/Freesurfer-based processing stream developed specifically for this project.  The code for this analysis stream is available at <a href="https://github.com/poldrack/openfmri">https://github.com/poldrack/openfmri</a>.  In addition, a nipype pipeline for this dataset has been developed by Satra Ghosh and is available at <a href="http://www.mit.edu/~satra/nipype-nightly/users/examples/fmri_openfmri.html">http://www.mit.edu/~satra/nipype-nightly/users/examples/fmri_openfmri.html</a>.</p>

<h4>Example Responses to Challenges</h4>

<p><strong>Challenge #1:</strong> Examine whether different task-relevant networks related to patterns of gene expression in the <a href="http://human.brain-map.org">Allen Human Brain Atlas</a>.</p>

<p><strong>Challenge #2:</strong> Integrate the resting state data with task data from the OpenfMRI database to identify the overlap and distinction between resting state networks and task-based networks.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Start Hacking with Data from ADNI]]></title>
    <link href="http://ohbm-seattle.github.io/blog/2013/04/21/start-hacking-with-data-from-adni/"/>
    <updated>2013-04-21T08:38:00-07:00</updated>
    <id>http://ohbm-seattle.github.io/blog/2013/04/21/start-hacking-with-data-from-adni</id>
    <content type="html"><![CDATA[<p><img src="https://ida.loni.ucla.edu/services/Images/Header/ADNI_Logo.png" title="height=150 &#34;ADNI&#34;" alt="height=150 &#34;ADNI&#34;"></p>

<p>Start responding to the hackathon challenges using data from ADNI - the <a href="http://www.adni-info.org">Alzheimer's Disease Neuroimaging Initiative</a>.</p>

<br />  




<!-- more -->


<p>The Alzheimer's Disease Neuroimaging Initiative (ADNI; <a href="http://www.adni-info.org">http://www.adni-info.org</a>) represents among the largest neuroimaging archive of data from Alzheimer's Disease (AD), Mild Cognitively Impaired (MCI), and healthy control subjects in the world. Now entering its third phase (ADNI, ADNI GO and ADNI 2), ADNI 2 is studying the rate of change of cognition, function, brain structure, and biomarkers in 150 controls, 450 MCI, 150 with mild to moderate AD and a new group of 100 people with significant, yet subtle, memory complaints, referred to as the significant memory concern cohort.  These data are openly available for analysis by approved scientists for research purposes, development of data processing methodologies, modeling, etc. Some conditions do apply, including that each person must gain access to the data through the normal application process and channels and the requested data may not be shared among other participants.  Full details on the data access policy are provided here (<a href="http://adni.loni.ucla.edu/data-samples/access-data">http://adni.loni.ucla.edu/data-samples/access-data</a>).</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The National Database for Autism Research Data Dive]]></title>
    <link href="http://ohbm-seattle.github.io/blog/2013/04/18/the-national-database-for-autism-research-data-dive/"/>
    <updated>2013-04-18T13:02:00-07:00</updated>
    <id>http://ohbm-seattle.github.io/blog/2013/04/18/the-national-database-for-autism-research-data-dive</id>
    <content type="html"><![CDATA[<p><img src="http://ndar.nih.gov/images/ndar/ndar.png" title="&#34;NDAR&#34;" alt="&#34;NDAR&#34;">
This HBM Hackathon accessible repository is an excellent resource for finding significant relationships amongst neuroimaging, clinical, and –omics data within the National Database for Autism Research (<a href="http://ndar.nih.gov">NDAR</a>).</p>

<!-- more -->


<h4>Background</h4>

<p><a href="http://ndar.nih.gov">NDAR</a> is an NIH-funded research data repository that aims to accelerate progress in autism spectrum disorders (ASD) research through data sharing, data harmonization, and the reporting of research results. NDAR is a restricted access data repository, offering a wealth of data related to human subjects research in autism.  Applying for access prior to the OHBM hack event is essential.  Additionally, it serves as a scientific community platform to multiple other research repositories, allowing for aggregation and secondary analysis of clinically captured research data.</p>

<h4>Data and Tools</h4>

<p>Continually updated through the contributions of primary researchers, NDAR provides authorized researchers access to contemporary relevant raw data in a relatively short amount of time after its collection.  The database currently is sharing data on <strong>48,135 individuals</strong> spread over <strong>64,335 subject / age time points</strong> across hundreds of clinical, omics, and imaging data structures harmonized using a common data dictionary and a common subject identifier (see <a href="http://ndar.nih.gov/ndar_data_dictionary.html">NDAR data dictionary</a>).  In addition to NDAR, autism data from the Autism Genetic Research Exchange, Interactive Autism Network, the Autism Tissue Program, and the normative Pediatric MRI data repository are also available, but also require approval.</p>

<h4>Details</h4>

<p>NDAR provides simple cohort selection/filtering on a variety of scores and types of data available at <a href="http://ndar.nih.gov/query_data.html">http://ndar.nih.gov/query_data.html</a>.  Data selected can be downloaded or pre-loaded onto an Amazon EC2 instance for evaluation using the <a href="http://www.nitrc.org/ce-forum">NITRC Computational Environment</a>, <a href="http://neuro.debian.net">NeuroDebian</a> or other available tool sets. NDAR’s rich datasets are stored in Amazon’s S3, which facilitates parallel processing and better transfer rates.</p>

<p>Download packages from NDAR include a single, tab-delimited text file for each data structure received, as well as any related files (e.g. imaging or omics) and a “Create Amazon RDS database” capability scheduled for May 2013.</p>

<h4>Getting Started</h4>

<p>NDAR is a restricted access data repository.  Review what’s available for download from <a href="http://ndar.nih.gov/query_data.html">http://ndar.nih.gov/query_data.html</a> and apply for access at <a href="http://ndar.nih.gov/ndarpublicweb/access.html">http://ndar.nih.gov/ndarpublicweb/access.html</a>.</p>
]]></content>
  </entry>
  
</feed>
