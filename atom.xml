<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[HBM Hackathon]]></title>
  <link href="http://ohbm-seattle.github.io/atom.xml" rel="self"/>
  <link href="http://ohbm-seattle.github.io/"/>
  <updated>2013-06-17T21:08:49-07:00</updated>
  <id>http://ohbm-seattle.github.io/</id>
  <author>
    <name><![CDATA[OHBM Organizing Committee]]></name>
    <email><![CDATA[hbm.hackathon@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Mindboggle 101: Manually labeled brain surfaces and volumes]]></title>
    <link href="http://ohbm-seattle.github.io/blog/2013/06/17/mindboggle-101-manually-labeled-brain-surfaces-and-volumes/"/>
    <updated>2013-06-17T17:03:00-07:00</updated>
    <id>http://ohbm-seattle.github.io/blog/2013/06/17/mindboggle-101-manually-labeled-brain-surfaces-and-volumes</id>
    <content type="html"><![CDATA[<p><img src="http://www.mindboggle.info/_static/mindboggle_logo_small.jpg"></p>

<p>Mindboggle-101: Manually labeled brain surfaces and volumes</p>

<!-- more -->


<p>The <a href="http://www.mindboggle.info/data/">Mindboggle-101</a> dataset includes manually labeled anatomical regions for 101 healthy subjects.  The manually edited cortical labels follow sulcus landmarks according to the Desikan-Killiany-Tourville (DKT) protocol. The protocol, individually labeled brain images, optimal average surface and volume templates, and a surface Gaussian classifier atlas are all available for download and are described in the following <a href="http://www.frontiersin.org/Brain_Imaging_Methods/10.3389/fnins.2012.00171/full">article</a>:</p>

<p>“101 labeled brain images and a consistent human cortical labeling protocol”
Arno Klein, Jason Tourville. Frontiers in Brain Imaging Methods. 6:171. DOI: 10.3389/fnins.2012.00171</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The 3rd HBM Hackathon challenge: Resources Mapped to MNI Space]]></title>
    <link href="http://ohbm-seattle.github.io/blog/2013/06/17/the-3rd-challenge-and-mapping-to-mni/"/>
    <updated>2013-06-17T07:10:00-07:00</updated>
    <id>http://ohbm-seattle.github.io/blog/2013/06/17/the-3rd-challenge-and-mapping-to-mni</id>
    <content type="html"><![CDATA[<p><img src="http://www.bic.mni.mcgill.ca/uploads/ServicesAtlases/mni_icbm152_sym_09a_small.jpg"></p>

<p>MNI Mashup: Most innovative map or aggregation of information in the MNI 152 standard.</p>

<!-- more -->


<p>This challenge challenge is to be addressed entirely during the meeting using resources made openly available to the brain mapping community.</p>

<p>Example projects:</p>

<ul>
<li>Aggregating standard MNI space 3D shape models of neuroanatomical structures</li>
<li><p>&#8220;Dense brain information map&#8221;. Given an (x,y,z,r) tell me everything you can about (x,y,z,r), especially including uncertainty of that information. Here are a few examples of information that could be returned:</p>

<ul>
<li>gene expression (and the uncertainty would be high if imputing and low if exactly at a probe location)</li>
<li>cognitive atlas terms and therefore publications and derivatives associated with that location ( a la neurosynth)</li>
<li>variation in cortical thickness</li>
<li>functional connectivity</li>
<li>likelihood of major fiber bundles in that location</li>
<li>registration inconsistency/uncertainty</li>
<li>cytoarchitecture variation (neuron types, etc.,.)</li>
<li>associated disorders</li>
<li>data from other species</li>
</ul>
</li>
</ul>


<p>Judging criteria:</p>

<ul>
<li>Scientific impact</li>
<li>Commitment to open availability of the resulting resource</li>
<li>Extensibility</li>
<li>Inclusion of quantified uncertainty</li>
</ul>


<p>Rules</p>

<ul>
<li>Participants must use publicly available data that is listed on the HBM Hackathon Blog. If a public dataset is not listed that you want to use, we would love to add it to the list, just contact us: hbm.hackathon@gmail.com</li>
<li>Participants can use any computational resources available to them, but judging will take into account innovative use of cloud computing and how openly available the approach is (see Judging)</li>
<li>At least one team leader/presenter must attend the meeting</li>
<li>Off-site team members are allowed and encouraged, but will not be eligible for all resources made available to registered OHBM attendees (e.g., cloud computing credits)</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[NeuroDebian: The ultimate neuroscience software platform]]></title>
    <link href="http://ohbm-seattle.github.io/blog/2013/06/11/neurodebian-the-ultimate-neuroscience-software-platform/"/>
    <updated>2013-06-11T18:00:00-07:00</updated>
    <id>http://ohbm-seattle.github.io/blog/2013/06/11/neurodebian-the-ultimate-neuroscience-software-platform</id>
    <content type="html"><![CDATA[<p><img src="http://ohbm-seattle.github.io/images/NeuroDebian.png" title="&#34;NeuroDebian&#34;" alt="&#34;NeuroDebian&#34;"></p>

<p><a href="http://neuro.debian.net">NeuroDebian</a> is a turnkey software platform for nearly all aspects of the neuroscientific research process.</p>

<!-- more -->


<p>NeuroDebian provides a large collection of popular neuroscience research software for the <a href="http://www.debian.org">Debian</a> operating system as well as <a href="http://www.ubuntu.com">Ubuntu</a> and other derivatives.  Moreover it provides some popular datasets and atlases within the same convenient package management system.</p>

<h3>Software</h3>

<p>Popular neuroscience-oriented packages include <a href="http://neuro.debian.net/pkgs/afni.html">AFNI</a>, <a href="http://neuro.debian.net/pkgs/fsl.html">FSL</a>, <a href="http://neuro.debian.net/pkgs/python-mvpa2.html">PyMVPA</a> and <a href="http://neuro.debian.net/pkgs.html">many others</a>. In addition popular projects for generic (e.g. <a href="http://neuro.debian.net/pkgs/python-pandas.html">pandas</a>, <a href="http://neuro.debian.net/pkgs/xppaut.html">xppaut</a>) and distributed (e.g., <a href="http://neuro.debian.net/pkgs/coop-computing-tools.html">coop-computing-tools</a>, <a href="http://neuro.debian.net/pkgs/condor.html">condor</a>) computation needs are included.  The <a href="http://neuro.debian.net/pkgs.html">entire list</a> is too long to cite here.</p>

<h3>Data</h3>

<ul>
<li>Atlases provided by software such as <a href="http://neuro.debian.net/pkgs/fsl.html">FSL</a> and <a href="http://neuro.debian.net/pkgs/afni.html">AFNI</a></li>
<li><a href="http://neuro.debian.net/pkgs/neurosynth-dataset.html">NeuroSynth dataset</a> and <a href="http://neuro.debian.net/pkgs/fsl-neurosynth-atlas.html">its FSL atlas</a></li>
<li><a href="http://neuro.debian.net/pkgs/haxby2001-faceobject.html">Haxby 2001</a> dataset</li>
<li><a href="http://neuro.debian.net/pkgs/python-mvpa2-tutorialdata.html">PyMVPA tutorial</a> (including data and IPython notebook)</li>
<li>See <a href="http://neuro.debian.net/pkglists/toc_pkgs_for_release_data.html">our website</a> for the exhaustive list</li>
</ul>


<h3>Installation</h3>

<p>Majority of software packaged by NeuroDebian team is integrated are already available on any stock <a href="http://www.debian.org">Debian</a> or <a href="http://www.ubuntu.com">Ubuntu</a> system.  In addition we maintain a dedicated <a href="http://neuro.debian.net/#get-neurodebian">NeuroDebian repository</a> which you could add to APT sources on your stock Debian/Ubuntu installation to obtain most recent versions and software we maintain AND data packages which are absent from official Debian and Ubuntu archives.</p>

<h4>Personal virtualization</h4>

<p>Pre-crafted <a href="http://neuro.debian.net/vm.html">NeuroDebian virtual appliance</a> allows to start using NeuroDebian and thousands of available software packages on any operating system in matter of minutes.</p>

<h4>Cloud</h4>

<p>NeuroDebian provides software for the NITRC-CE environment available for the hackathon participants.</p>

<h3>Support</h3>

<p><a href="mailto:team@neuro.debian.net">Email us directly</a> with any &#8220;private&#8221; communication. Otherwise please use our <a href="http://lists.alioth.debian.org/mailman/listinfo/neurodebian-users">public mailing list</a> with any support questions.</p>

<p>You are welcome also to join #neurodebian IRC room on OFTC network if you have quick questions or want to join a live discussion.</p>

<p>Please visit our <a href="http://neuro.debian.net/about.html#chap-contacts">support</a> page for additional channels.</p>

<h3>Conclusion</h3>

<p>If you are not using NeuroDebian <em>already</em> - you must try it now!</p>

<!-- some packages worth mentioning -->



]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[NIF: an inventory of Web-based neuroscience resources]]></title>
    <link href="http://ohbm-seattle.github.io/blog/2013/05/29/nif-an-inventory-of-web-based-neuroscience-resources/"/>
    <updated>2013-05-29T14:03:00-07:00</updated>
    <id>http://ohbm-seattle.github.io/blog/2013/05/29/nif-an-inventory-of-web-based-neuroscience-resources</id>
    <content type="html"><![CDATA[<p><img src="http://www.neuinfo.org/images/nif-logo.png" width="75" title="&#34;NIF&#34;" alt="&#34;NIF&#34;"></p>

<p>The <a href="http://www.neuinfo.org">Neuroscience Information Framework</a>: neuroscience data, materials, and tools  via any computer connected to the Internet.</p>

<!-- more -->


<h4>Background</h4>

<p>Currently NIF Offers:</p>

<ol>
<li>A <a href="http://www.neuinfo.org/nif/nifgwt.html">search</a> portal for researchers looking for neuroscience information, tools, data or materials</li>
<li>Access to content normally not indexed by search engines (i.e, the &#8220;hidden web&#8221;)</li>
<li><a href="http://neuinfo.org/nif_components/disco/interoperation.shtm">Tools</a> for promoting interoperability among databases</li>
<li>The <a href="http://www.neuinfo.org/vocabularies/index.shtm">NIFSTD ontology</a> covering the major domains of neuroscience (e.g., brain anatomy, cells, organisms, diseases, techniques)</li>
<li><a href="http://www.neuinfo.org/developers/index.shtm">Developer resources</a> for accessing the NIF vocabulary and NIF tools, such as <a href="http://neuinfo.org/developers/nif_web_services.shtm">web services</a> and including a <a href="http://neuinfo.org/tutorials/developers_tool/federated_data.shtm">tutorial</a></li>
</ol>


<p>Some particular data sets which can be offered are Brain Connectivity Data (50316 records), Brain Activation Foci (5,145), Diseases (1,521), Microarray (642,995):</p>

<ul>
<li><a href="https://www.neuinfo.org/mynif/search.php?q=connectivity&amp;first=true&amp;cf=Connectivity">Integrated Nervous System Connectivity View</a> is an aggregated dataset of connectivity statements from BAMS, CoCoMac, BrainMaps, Connectome Wiki, the Hippocampal-Parahippocampal Table of Temporal-Lobe.com and the Avian Brain Circuitry Database.</li>
<li><a href="https://www.neuinfo.org/mynif/search.php?q=connectivity&amp;first=true&amp;cf=Disease&amp;t=indexable&amp;nif=nlx_86401-1">Integrated Disease View</a> is a virtual database currently indexing authoritative information on disease and treatment options from: NINDS Disorder List and PubMed Health.</li>
<li><a href="https://www.neuinfo.org/mynif/search.php?q=connectivity&amp;first=true&amp;cf=Brain%20Activation%20Foci">Activation Foci</a> data provides functional activation foci data from published neuroimaging studies.</li>
</ul>


<h4>Example Responses to Challenges</h4>

<p><strong>Challenge 1:</strong></p>

<ul>
<li>Use NIF neuron registry to identify cell systems in various neurodegenerative diseases and map it to ABA data.</li>
<li>For different diseases, use NeuronRegistry-NeuroLex to infer from genes what specific cell populations differently effect neuron types. Also, we&#8217;d like to link those cell systems in Neurodegenerative diseases to neurotransmitter data in NeuronRegistry.</li>
<li>For example, in Alzheimer we want to examine ABA genes and how differently they affect different group of neurons found in NeuronRegistry. Infer what cell populations impacted in various brain regions.</li>
<li>ABA has mapped neurotransmitter related genes, thus one challenge is: <strong>Are there specific neurotransmitter systems affected in mental disorders and do they map to any known cell type?</strong></li>
</ul>


<p><strong>Challenge 2:</strong></p>

<p>Use NIF cell data as a bridge between resting data and projections of know cell types in various brain regions (ABA). Use Neurolex (NIF) and tractography (NIF) data we can estimate what type of cells where can cell body are and where axon projected.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Explore and get public fMRI datasets from COINS Data Exchange]]></title>
    <link href="http://ohbm-seattle.github.io/blog/2013/05/14/explore-and-get-public-fmri-datasets-from-coins-data-exchange/"/>
    <updated>2013-05-14T13:29:00-07:00</updated>
    <id>http://ohbm-seattle.github.io/blog/2013/05/14/explore-and-get-public-fmri-datasets-from-coins-data-exchange</id>
    <content type="html"><![CDATA[<p><img src="http://d1yzvr466z4u1c.cloudfront.net/image02.jpg" alt="COINS Banner" style="width:100%;" /></p>

<p>COINS manages fMRI, MEG and phenotypic data for over 400 studies across six research institutions.</p>

<!-- more -->


<p>An ever-increasing subset of this data is being made publicly available on the COINS Data Exchange. Currently, the research community can explore and request raw MRI, fMRI and phenotypic data from several independent studies.</p>

<h3>Tutorial:</h3>

<p>A simple video-tutorial for querying can be seen on the COINS Data Exchange site, or on <a href="http://www.youtube.com/watch?v=YjMbCq5NBuc">YouTube</a>.</p>

<div class="embed-video-container"><iframe src="http://www.youtube.com/embed/YjMbCq5NBuc "></iframe></div>


<h3>Exploration:</h3>

<p>Creating a COINS account is easy. Just go to <a href="http://coins.mrn.org/dx">http://coins.mrn.org/dx</a>, enter your email address, make up a password and click ‘Get Account’.  That account is needed to let you know when your data are available for download, and to track any data agreements necessary for specific datasets. It is recommended that you do this prior to the Hackathon, just to explore the Data Exchange before needing to use it.</p>

<p>Once your account has been created, you can browse data in the Data Exchange. A unique filtering tool allows you to construct complex queries by combining data filters into logical groups and sub-groups. The goal of the exploration should be to target the exact data that is useful to you before you request and download it. This will save bandwidth and computing time on the COINS servers. Additionally, a well-targeted request will save you time by decreasing the need to post-filter data after download.</p>

<h3>Approval:</h3>

<p>Once you have found your ideal data, you can request that data by clicking the ‘Request’ button at the top-right. Though all data in the COINS data exchange is fully anonymized and defaced, some studies will need to explicitly approve your request. For this reason, you can provide information about your intentions for the data that you are requesting. Other studies (ABIDE, for example) have pre-approved their data for instant download. Each data-source is approved independently, so you can start downloading data as it is approved.</p>

<h3>Delivery:</h3>

<p>Approved data is packaged into ‘Data Capsules’ on the COINS servers. You will receive an email when your Data Capsule is ready, and you can then begin your download(s).</p>

<h3>Using COINS Data Exchange to meet your OHBM Hackathon objectives:</h3>

<p>At present, the COINS Data Exchange is only accessible through the browser interface at <a href="http://coins.mrn.org/dx">http://coins.mrn.org/dx</a>. However, once your data has been approved and packaged for download, you can download each data capsule directly to another web-server or cloud-based storage device from the command line or a script.</p>

<p>After choosing which capsule to download, a dialog will appear with a temporary URL that can be used to request the capsule directly. The link will expire as soon as the download button is clicked, or after five minutes, so please do not click on the data until you are ready to download it..
<img src="http://d1yzvr466z4u1c.cloudfront.net/image01.png" alt="COINS Banner" style="max-width:100%;" /></p>

<p>Downloaded imaging data may consist of DICOM or NIfTI files, and will be organized in the following file-hierarchy:</p>

<p><img src="http://d1yzvr466z4u1c.cloudfront.net/image00.png" alt="COINS Banner" style="max-width:100%" /></p>

<p>Downloaded phenotypic (assessment) data will be contained in CSV files: one per instrument (questionnaire form).</p>

<h3>Currently Available Datasets:</h3>

<ul>
<li><p><strong>ABIDE:</strong> from <a href="http://fcon_1000.projects.nitrc.org/indi/abide/">http://fcon_1000.projects.nitrc.org/indi/abide/</a>: In response, the Autism Brain Imaging Data Exchange (ABIDE) hereby provides previously collected resting state functional magnetic resonance imaging (R-fMRI) datasets from 539 individuals with ASD and 573 typical controls for the purpose of data sharing in the broader scientific community. Various cognitive and clinical assessments are also available. These data are pre-approved for sharing.</p></li>
<li><p><strong>Discovery Sci:</strong> <a href="http://fcon_1000.projects.nitrc.org/indi/pro/nki.html">http://fcon_1000.projects.nitrc.org/indi/pro/nki.html</a>: The NKI/Rockland Sample is intended to be a phenotypically rich neuroimaging sample, consisting of data obtained from individuals between the ages of 4 and 85 year-old. All individuals to be included in the sample undergo semi-structured diagnostic psychiatric interviews, and complete a battery of psychiatric, cognitive and behavioral assessments in order to provide comprehensive phenotypic information for the purpose of exploring brain/behavior relationships. Data from the NKI/Rockland sample will be given away prospectively, during the course of acquisition (randomized 2-8 week lag). These data require a data sharing agreement which can be quickly approved.</p></li>
<li><p><strong>MCIC:</strong> The MIND Clinical Imaging Consortium is composed of The Mental Illness and Neuroscience Discovery Institute, now the Mind Research Network (MRN, <a href="http://mrn.org">http://mrn.org</a>), comprised of investigators at the University of New Mexico, the University of Minnesota, Massachusetts General Hospital, and the University of Iowa (data from this site not available). The MCIC consortium conducted a cross-sectional study to identify quantitative neuroimaging biomarkers of schizophrenia. Expertly collected, well-curated data sets consisting of comprehensive clinical characterization and raw structural, functional and diffusion-weighted DICOM images in schizophrenia patients (n=162) and sex and age-matched controls (n=169) are now accessible to the scientific community. These data also require a data sharing agreement which can be quickly approved.</p></li>
</ul>


<h3>Contact:</h3>

<p>The COINS developers are excited to support the OHBM Hackathon participants. Any requests, questions or feedback can be directed to <a href="&#109;&#97;&#105;&#108;&#x74;&#x6f;&#x3a;&#110;&#105;&#x40;&#x6d;&#x72;&#110;&#x2e;&#111;&#x72;&#103;">&#110;&#x69;&#x40;&#x6d;&#114;&#110;&#46;&#111;&#x72;&#x67;</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[NITRC-CE: A computational resource for the HBM Hackathon]]></title>
    <link href="http://ohbm-seattle.github.io/blog/2013/05/13/nitrc-ce-a-cloud-based-computational-resource-for-the-hbm-hackathon/"/>
    <updated>2013-05-13T12:00:00-07:00</updated>
    <id>http://ohbm-seattle.github.io/blog/2013/05/13/nitrc-ce-a-cloud-based-computational-resource-for-the-hbm-hackathon</id>
    <content type="html"><![CDATA[<p><img src="http://ohbm-seattle.github.io/images/NITRC-CE.png" title="&#34;NITRC-CE&#34;" alt="&#34;NITRC-CE&#34;"></p>

<p>NITRC-CE is an on-demand, cloud based computational virtual machine pre-installed with popular NITRC neuroimaging tools.</p>

<!-- more -->


<p>In January of 2013, the Neuroimaging Informatics Tools and Resources Clearinghouse (<a href="http://www.nitrc.org">NITRC</a>) released it&#8217;s Computational Environment (NITRC-CE), an on-demand, cloud based computational virtual machine pre-installed with popular NITRC neuroimaging tools built using NeuroDebian.</p>

<h3>Purpose</h3>

<p>The NITRC-CE is designed to be a low-barrier entry point to accessing the power of the cloud-based computing environment by providing a fully configured, ready to go EC2 instance within just a few clicks of the mouse.</p>

<h3>Access</h3>

<p>NITRC-CE is available via the <a href="https://aws.amazon.com/marketplace/pp/B00AW0MBLO">Amazon Marketplace</a>. In addition,  you can also access a &#8216;public AMI&#8217; to conduct your analyses on the Amazon EC2 platform.  The NITRC-CE is scalable and extensible, and preconfigured with many <a href="http://www.nitrc.org/plugins/mwiki/index.php/nitrc:User_Guide_-_NITRC-CE_Installed_Packages">software packages</a>. Additional software supported under Ubuntu 12.04 LTE can be added by the user.</p>

<h3>Data</h3>

<p>Each NITRC-CE instance has remote access, so that users own data can be copied to and from using &#8216;scp&#8217; and &#8216;sftp&#8217;. In addition, The NITRC-CE desktop is one-click away from the NITRC Image Repository (NITRC-IR), home of data for the 1000 Functional Connectomes, ADHD-200, ABIDE and other datasets. In addition, the NDAR download manager is available to assist in access to your NDAR datasets. Additional access points to other Hackathon data will be added in the near future.</p>

<h3>Support</h3>

<p>The staff of NITRC are available to assist users with issues (<strong><a href="&#x6d;&#x61;&#105;&#x6c;&#116;&#111;&#x3a;&#x6e;&#105;&#x74;&#114;&#105;&#x63;&#105;&#x6e;&#102;&#x6f;&#x40;&#110;&#105;&#x74;&#x72;&#99;&#x2e;&#111;&#114;&#x67;">&#x6e;&#x69;&#x74;&#x72;&#105;&#x63;&#105;&#110;&#x66;&#111;&#x40;&#110;&#x69;&#116;&#x72;&#x63;&#x2e;&#x6f;&#114;&#103;</a></strong>), and a comprehensive <a href="http://www.nitrc.org/plugins/mwiki/index.php/nitrc:User_Guide_-_NITRC_Computational_Environment">Users Guide</a> and discussion forum dedicated to <a href="http://www.nitrc.org/forum/forum.php?thread_id=3897&amp;forum_id=3663">HBM Hackathon support</a>.</p>

<h3>Conclusion</h3>

<p>Best of luck in your participation in the HBM Hackathon. We hope the NITRC-CE will be a valuable resource to you.  Feel free to contact us with any questions, problems or suggestions for enhanced support of this endeavor.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Human Connectome Project Q1 Release: Now Cloud Accessible]]></title>
    <link href="http://ohbm-seattle.github.io/blog/2013/05/03/human-connectome-project-q1-release-now-cloud-accessible/"/>
    <updated>2013-05-03T13:00:00-07:00</updated>
    <id>http://ohbm-seattle.github.io/blog/2013/05/03/human-connectome-project-q1-release-now-cloud-accessible</id>
    <content type="html"><![CDATA[<p><img src="http://www.humanconnectome.org/img/header-bg.png" title="&#34;Human Connectom Project&#34;" alt="&#34;Human Connectom Project&#34;"></p>

<p>The <a href="http://www.humanconnectome.org/data/">first full quarterly HCP Data release</a> is now Cloud accessible for participants who have <a href="http://www.humanconnectome.org/data/data-use-terms/index.html">registered</a> and agreed to the <a href="http://www.humanconnectome.org/data/data-use-terms/open-access.html">Open Access Data Use Terms</a>.</p>

<!-- more -->


<p>HBM Hackathon participants will have the opportunity for high speed access to the first full quarterly HCP Data release via Amazon Web Services. All data available from the HCP Connectome-in-a-Box can now be downloaded directly from S3, Amazon’s Simple Storage Service.</p>

<h4>This post is organized into three sections:</h4>

<ol>
<li>Description of the HCP Q1 Release</li>
<li>Getting Authorized to Access the HCP Data</li>
<li>Accessing HCP Data on AWS</li>
</ol>


<h3>Description of the HCP Q1 Release</h3>

<p>The Q1 data release consists of multimodal MRI data collected from 68 healthy young adults who were scanned in the fall of 2012. These include all 12 subjects from our Initial Data Release. All 3T MRI scan data is included: Structural, Functional (resting state and task) and Diffusion. Behavioral data collected on all subjects is also included, with the exception of sensitive restricted-access data. Please see the <a href="http://www.humanconnectome.org/documentation/Q1/">Full Release Documentation</a> for further details.</p>

<h3>Getting Authorized to Access the HCP Data</h3>

<p>There are a few steps you will need to take to get authorization to access the HCP data hosted on AWS.</p>

<h4>You need to:</h4>

<ol>
<li>Complete the <strong><a href="http://www.humanconnectome.org/data/data-use-terms/index.html">HCP Registration</a></strong> and agree to the <strong><a href="http://www.humanconnectome.org/data/data-use-terms/open-access.html">HCP Open Access Data Use Terms</a></strong></li>
<li>Complete the <strong><a href="http://www.humanbrainmapping.org/hackathon">HBM Hackathon Registration</a></strong></li>
<li>Create an <strong><a href="http://aws.amazon.com/">Amazon Web Services Account</a></strong></li>
<li>Email <strong><a href="&#x6d;&#97;&#105;&#x6c;&#x74;&#111;&#58;&#104;&#98;&#x6d;&#x2e;&#104;&#x61;&#99;&#107;&#x61;&#x74;&#104;&#111;&#110;&#x40;&#103;&#109;&#x61;&#x69;&#108;&#x2e;&#99;&#x6f;&#109;">&#104;&#98;&#109;&#x2e;&#104;&#x61;&#x63;&#107;&#x61;&#116;&#104;&#x6f;&#110;&#x40;&#x67;&#109;&#97;&#x69;&#108;&#46;&#x63;&#x6f;&#109;</a></strong> with your HCP and AWS email address(es)</li>
</ol>


<h4>A foreword from David van Essen:</h4>

<blockquote><p><strong>For distribution to all investigators interested in using HCP Connectome-in-a-Box data.</strong><br/>
</br>
<strong>IMPORTANT NOTICE to investigators wanting to use HCP datasets available on Connectome-in-a-Box hard drives.</strong><br/>
</br>
HCP’s Connectome-in-a-Box provides imaging data from the Open Access dataset. Before using any of these data for research, you and all other investigators using the data are required to <a href="http://www.humanconnectome.org/data/data-use-terms/index.html">register</a> and agree to the <a href="http://www.humanconnectome.org/data/data-use-terms/open-access.html">Open Access Data Use Terms</a>. <strong>This includes agreeing to comply with institutional rules and regulations</strong>.  This may mean that you need your research to be approved or declared exempt by a committee that oversees research on human subjects (e.g., your IRB or Ethics Committee).  The released HCP data are not considered de-identified, insofar as certain combinations of HCP Restricted Data (available through a separate process) might allow identification of individuals.  Different committees operate under different national, state and local laws and may interpret regulations differently, so it is important to ask about this. If needed and upon request, the HCP will provide a certificate stating that you have accepted the HCP Open Access Data Use Terms.<br/>
</br>
Sincerely,<br/>
David C. Van Essen (PI), for the WU-Minn HCP Consortium<br/>
May 1, 2013</p></blockquote>

<h3>Accessing HCP Data on AWS</h3>

<p>Amazon Web Services is hosting the HCP Q1 Data Release as part of its Public Data Sets on AWS program, which will enable HBM Hackathon participants to get rapid access to the HCP data. Since the data is hosted on S3 in an uncompressed format, participants can download data in parallel using tools like <a href="https://github.com/pcorliss/s3cmd-modification">s3cmd-modification</a>.</p>

<p>You can use tools like <a href="https://github.com/pcorliss/s3cmd-modification">s3cmd</a> to list the contents of a directory on S3, get individual files or sync full directories. You will also be able to download directly to your personal/work computer or to a machine on the EC2 Cloud like the <a href="https://aws.amazon.com/marketplace/pp/B00AW0MBLO">NITRC Computational Environment</a>.</p>

<h4>Getting Credentials</h4>

<p>Ready to start downloading? Make sure you&#8217;ve completed the <a href="http://www.humanconnectome.org/data/data-use-terms/index.html">HCP registration</a> and <a href="http://aws.amazon.com/">created an account with AWS</a>.</p>

<p>Next, send an email to <strong><a href="&#x6d;&#x61;&#x69;&#x6c;&#116;&#111;&#58;&#104;&#98;&#109;&#46;&#x68;&#97;&#x63;&#x6b;&#x61;&#x74;&#x68;&#x6f;&#110;&#x40;&#103;&#x6d;&#x61;&#105;&#108;&#x2e;&#99;&#x6f;&#109;">&#104;&#98;&#x6d;&#x2e;&#x68;&#97;&#x63;&#x6b;&#97;&#116;&#104;&#x6f;&#x6e;&#64;&#103;&#109;&#x61;&#x69;&#x6c;&#46;&#x63;&#111;&#109;</a></strong> with your HCP and AWS email address(es).</p>

<p>We will use your HCP and AWS email address(es) to:</p>

<ol>
<li>verify that you have agreed to the <a href="http://www.humanconnectome.org/data/data-use-terms/open-access.html">Open Access Data Use Agreement</a></li>
<li>grant you access to the HCP data on AWS.</li>
</ol>


<p>Once verified, you will receive an email confirming that you have access to the HCP data on AWS.</p>

<h4>Configuring your system</h4>

<p>To access the data you&#8217;ll want to install <a href="https://github.com/pcorliss/s3cmd-modification">s3cmd-modification</a>, which will enable you to explore the <a href="http://humanconnectome.org/documentation/data-release/Q1_Release_Appendix_III.pdf">HCP Data Directory</a> on Amazon and will allow rapid parallel downloading (<a href="https://github.com/pcorliss/s3cmd-modification/blob/master/INSTALL">s3cmd-modification install instructions</a>).</p>

<p>After you install s3cmd, you need to configure it with your AWS public and secret keys, located in <a href="https://portal.aws.amazon.com/gp/aws/securityCredentials">AWS Security Credentials</a>.</p>

<pre><code>:~ s3cmd --configure
Enter new values or accept defaults in brackets with Enter.
Refer to user manual for detailed description of all options.

Access key and Secret key are your identifiers for Amazon S3
Access Key []: &lt;your-access-key&gt;
Secret Key []: &lt;your-secret-key&gt;
... 
</code></pre>

<p>Take s3cmd out for a test drive&#8230;</p>

<p>List subject directories:</p>

<pre><code>:~ s3cmd ls s3://hcp.aws.amazon.com/q1/

DIR   s3://hcp.aws.amazon.com/q1/100307/
DIR   s3://hcp.aws.amazon.com/q1/103515/
DIR   s3://hcp.aws.amazon.com/q1/111312/
...
DIR   s3://hcp.aws.amazon.com/q1/937160/
2013-04-17 06:57         0   s3://hcp.aws.amazon.com/q1/
</code></pre>

<p>Get a directory in parallel:</p>

<pre><code>:~ s3cmd --parallel --workers=16 get --recursive s3://hcp.aws.amazon.com/q1/100307/T1w T1w

File s3://hcp.aws.amazon.com/q1/100307/T1w/BiasField_acpc_dc.nii.gz started [2 of 52]
File s3://hcp.aws.amazon.com/q1/100307/T1w/Native/100307.L.MyelinMap.native.func.gii started [3 of 52]
...
File s3://hcp.aws.amazon.com/q1/100307/T1w/T2w_acpc_dc_restore.nii.gz saved as 'T1w/T1w/T2w_acpc_dc_restore.nii.gz' (67855816 bytes in 143.3 seconds, 462.31 kB/s)
File s3://hcp.aws.amazon.com/q1/100307/T1w/BiasField_acpc_dc.nii.gz saved as 'T1w/T1w/BiasField_acpc_dc.nii.gz' (65076318 bytes in 180.3 seconds, 352.50 kB/s)
</code></pre>

<p>If everything checks out, you are ready to get hacking!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[OpenfMRI Now an HBM Hackathon Resource]]></title>
    <link href="http://ohbm-seattle.github.io/blog/2013/04/22/openfmri-now-an-hbm-hackathon-resource/"/>
    <updated>2013-04-22T14:28:00-07:00</updated>
    <id>http://ohbm-seattle.github.io/blog/2013/04/22/openfmri-now-an-hbm-hackathon-resource</id>
    <content type="html"><![CDATA[<p><img src="https://openfmri.org/sites/all/themes/openfmri/logo.png" title="height=150 &#34;OpenfMRI&#34;" alt="height=150 &#34;OpenfMRI&#34;"></p>

<p>The <a href="http://openfmri.org">OpenfMRI</a> project provides raw and processed task fMRI datasets for use in re-analysis and mega-analysis that are now Cloud accessible.</p>

<!-- more -->


<h4>Background</h4>

<p>Currently the OpenfMRI database contains data from 18 studies (totaling 374 scanning sessions) across a wide range of different cognitive task domains, including: visual perception (object recognition, mirror reading), language processing (semantic judgments, rhyme judgments, pseudoword reading), working memory (tone counting, 1-back), cognitive control (stop signal, flanker, and Simon tasks), learning (category learning), decision making (gambling task, balloon analog risk task), memory encoding emotion regulation (reappraisal task), and social perception (false belief task).</p>

<p>More details about these datasets can be obtained from <a href="http://openfmri.org/data-sets">http://openfmri.org/data-sets</a>. The data will also be made available via AWS.</p>

<h4>Processing</h4>

<p>The data have been preprocessed and analyzed through a full group-level fMRI analysis, using an automated FSL/Freesurfer-based processing stream developed specifically for this project.  The code for this analysis stream is available at <a href="https://github.com/poldrack/openfmri">https://github.com/poldrack/openfmri</a>.  In addition, a nipype pipeline for this dataset has been developed by Satra Ghosh and is available at <a href="http://www.mit.edu/~satra/nipype-nightly/users/examples/fmri_openfmri.html">http://www.mit.edu/~satra/nipype-nightly/users/examples/fmri_openfmri.html</a>.</p>

<h4>Example Responses to Challenges</h4>

<p><strong>Challenge #1:</strong> Examine whether different task-relevant networks related to patterns of gene expression in the <a href="http://human.brain-map.org">Allen Human Brain Atlas</a>.</p>

<p><strong>Challenge #2:</strong> Integrate the resting state data with task data from the OpenfMRI database to identify the overlap and distinction between resting state networks and task-based networks.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Start Hacking with Data from ADNI]]></title>
    <link href="http://ohbm-seattle.github.io/blog/2013/04/21/start-hacking-with-data-from-adni/"/>
    <updated>2013-04-21T08:38:00-07:00</updated>
    <id>http://ohbm-seattle.github.io/blog/2013/04/21/start-hacking-with-data-from-adni</id>
    <content type="html"><![CDATA[<p><img src="https://ida.loni.ucla.edu/services/Images/Header/ADNI_Logo.png" title="height=150 &#34;ADNI&#34;" alt="height=150 &#34;ADNI&#34;"></p>

<p>Start responding to the hackathon challenges using data from ADNI - the <a href="http://www.adni-info.org">Alzheimer&#8217;s Disease Neuroimaging Initiative</a>.</p>

<br />  




<!-- more -->


<p>The Alzheimer&#8217;s Disease Neuroimaging Initiative (ADNI; <a href="http://www.adni-info.org">http://www.adni-info.org</a>) represents among the largest neuroimaging archive of data from Alzheimer&#8217;s Disease (AD), Mild Cognitively Impaired (MCI), and healthy control subjects in the world. Now entering its third phase (ADNI, ADNI GO and ADNI 2), ADNI 2 is studying the rate of change of cognition, function, brain structure, and biomarkers in 150 controls, 450 MCI, 150 with mild to moderate AD and a new group of 100 people with significant, yet subtle, memory complaints, referred to as the significant memory concern cohort.  These data are openly available for analysis by approved scientists for research purposes, development of data processing methodologies, modeling, etc. Some conditions do apply, including that each person must gain access to the data through the normal application process and channels and the requested data may not be shared among other participants.  Full details on the data access policy are provided here (<a href="http://adni.loni.ucla.edu/data-samples/access-data">http://adni.loni.ucla.edu/data-samples/access-data</a>).</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[LONI Pipeline in the Cloud]]></title>
    <link href="http://ohbm-seattle.github.io/blog/2013/04/18/loni-pipeline-in-the-cloud/"/>
    <updated>2013-04-18T14:30:00-07:00</updated>
    <id>http://ohbm-seattle.github.io/blog/2013/04/18/loni-pipeline-in-the-cloud</id>
    <content type="html"><![CDATA[<p><img src="http://pipeline.loni.ucla.edu/wp-content/themes/pipeline2012/images/explore_Coin.jpg" title="height=150 &#34;LONI Pipeline&#34;" alt="height=150 &#34;LONI Pipeline&#34;"></p>

<p>The <a href="http://pipeline.loni.ucla.edu" title="LONI Pipeline">LONI Pipeline</a> is available on the Cloud as an <a href="http://pipeline.loni.ucla.edu/products-services/pipeline-server-on-ec2" title="Pipeline on EC2">Amazon EC2 Instance</a> (i.e., virtual machine) with access to several datasets.</p>

<!-- more -->


<p> Both free and paid AWS/EC2 subscriptions can be used to launch the DPS (Distributed Pipeline Server) on EC2, and click Launch Instance. Then remote clients can connect to the hostname of that instance (e.g., ec2-184-73-1-1.compute-1.amazonaws.com). After connecting to the server, you can open a workflow under Server Library and run. The Pipeline library includes 100’s of imaging and genetics software suites, atomic processing tools, datasets and resources.  For additional details on LONI Pipeline, please see <a href="http://pipeline.loni.ucla.edu">http://pipeline.loni.ucla.edu</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The National Database for Autism Research Data Dive]]></title>
    <link href="http://ohbm-seattle.github.io/blog/2013/04/18/the-national-database-for-autism-research-data-dive/"/>
    <updated>2013-04-18T13:02:00-07:00</updated>
    <id>http://ohbm-seattle.github.io/blog/2013/04/18/the-national-database-for-autism-research-data-dive</id>
    <content type="html"><![CDATA[<p><img src="http://ndar.nih.gov/images/ndar/ndar.png" title="&#34;NDAR&#34;" alt="&#34;NDAR&#34;">
This HBM Hackathon accessible repository is an excellent resource for finding significant relationships amongst neuroimaging, clinical, and –omics data within the National Database for Autism Research (<a href="http://ndar.nih.gov">NDAR</a>).</p>

<!-- more -->


<h4>Background</h4>

<p><a href="http://ndar.nih.gov">NDAR</a> is an NIH-funded research data repository that aims to accelerate progress in autism spectrum disorders (ASD) research through data sharing, data harmonization, and the reporting of research results. NDAR is a restricted access data repository, offering a wealth of data related to human subjects research in autism.  Applying for access prior to the OHBM hack event is essential.  Additionally, it serves as a scientific community platform to multiple other research repositories, allowing for aggregation and secondary analysis of clinically captured research data.</p>

<h4>Data and Tools</h4>

<p>Continually updated through the contributions of primary researchers, NDAR provides authorized researchers access to contemporary relevant raw data in a relatively short amount of time after its collection.  The database currently is sharing data on <strong>48,135 individuals</strong> spread over <strong>64,335 subject / age time points</strong> across hundreds of clinical, omics, and imaging data structures harmonized using a common data dictionary and a common subject identifier (see <a href="http://ndar.nih.gov/ndar_data_dictionary.html">NDAR data dictionary</a>).  In addition to NDAR, autism data from the Autism Genetic Research Exchange, Interactive Autism Network, the Autism Tissue Program, and the normative Pediatric MRI data repository are also available, but also require approval.</p>

<h4>Details</h4>

<p>NDAR provides simple cohort selection/filtering on a variety of scores and types of data available at <a href="http://ndar.nih.gov/query_data.html">http://ndar.nih.gov/query_data.html</a>.  Data selected can be downloaded or pre-loaded onto an Amazon EC2 instance for evaluation using the <a href="http://www.nitrc.org/ce-forum">NITRC Computational Environment</a>, <a href="http://neuro.debian.net">NeuroDebian</a> or other available tool sets. NDAR’s rich datasets are stored in Amazon’s S3, which facilitates parallel processing and better transfer rates.</p>

<p>Download packages from NDAR include a single, tab-delimited text file for each data structure received, as well as any related files (e.g. imaging or omics) and a “Create Amazon RDS database” capability scheduled for May 2013.</p>

<h4>Getting Started</h4>

<p>NDAR is a restricted access data repository.  Review what’s available for download from <a href="http://ndar.nih.gov/query_data.html">http://ndar.nih.gov/query_data.html</a> and apply for access at <a href="http://ndar.nih.gov/ndarpublicweb/access.html">http://ndar.nih.gov/ndarpublicweb/access.html</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Challenge #1: Allen Human Brain Atlas Integration]]></title>
    <link href="http://ohbm-seattle.github.io/blog/2013/04/15/challenge-number-1-allen-human-brain-atlas-integration/"/>
    <updated>2013-04-15T12:00:00-07:00</updated>
    <id>http://ohbm-seattle.github.io/blog/2013/04/15/challenge-number-1-allen-human-brain-atlas-integration</id>
    <content type="html"><![CDATA[<p><img src="http://www.alleninstitute.org/Assets/images/common/logo_institute.png" title="&#34;Allen Institute for Brain Science&#34;" alt="&#34;Allen Institute for Brain Science&#34;">
For this challenge, you will try to identify the best relationship between
imaging data and gene expression data in the Allen Human Brain Atlas.</p>

<!-- more -->


<h4>Background</h4>

<p>The goal of the Allen Human Brain Atlas is to create a comprehensive map of
transcript usage across the entire adult brain, with the emphasis on anatomically complete coverage in a small number of high-quality, clinically unremarkable brains profiled with DNA microarrays for quantitative gene-level transcriptome coverage. Further, structural brain imaging data were obtained from each individual to visualize gene expression data in its native 3D anatomical coordinate space, and to allow correlations between imaging and transcriptome modalities.</p>

<h4>Data and Tools</h4>

<p>The Atlas consists of microarray profiles of 3702 neuroanatomically precise
subdivisions sampled over six individuals (5 males, 1 female). Each gene
expression profile contains information for over 58,000 gene probes with
93% of known genes represented by at least 2 probes. Sample locations were
mapped back into the native brain MRI coordinates and subsequently to Montreal Neurological Institute (MNI) coordinate space.</p>

<p>These data are freely accessible via the Allen Brain Atlas data portal (<a href="http://human.brain-map.org">http://human.brain-map.org</a>).  They have also been mirrored using Amazon&#8217;s AWS S3 cloud storage <a href="https://s3.amazonaws.com/Human-Brain-Atlas/index.html">here</a>.</p>

<p>Use the online tools to visualize the expression data as heatmaps or projected into 3D anatomical context. An integrated data service allows users to perform differential and correlative searches to discover genes of interest.</p>

<p>For more detail, start with a <a href="http://www.brain-map.org/tutorials/index">guided overview</a> or see the recent <a href="http://www.nature.com/nature/journal/v489/n7416/full/nature11405.html">publication</a> in Nature.</p>

<h4>Details</h4>

<p>The data is divided into separate .zip files each of the 6 donors. The zip file contains:</p>

<ul>
<li>SampleAnnot.csv: describes every microarray sample. Structures and MNI coordinates are here.</li>
<li>MicroarrayExpression.csv: normalized expression values for all samples and probes.</li>
<li>Probes.csv: description of the probes and their genes.</li>
<li>Ontology.csv: all structures in the hierarchical ontology. The &#8216;structure_id_path&#8217; column describes the parent-child relationship.</li>
<li>Contents.txt: a more detailed description of the .zip contents.</li>
</ul>


<h4>Getting Started</h4>

<p>We&#8217;re looking for the best relationship between gene expression in the Atlas and imaging data set. You are not restricted to any particular imaging data set.</p>

<p>This <a href="http://api.brain-map.org/examples/spm/index.html">sample Matlab code</a> that might be a good place to start. It takes one of the example data sets from the Statistical Parametric Mapping (SPM) package, samples the image at all of the microarray sample MNI coordinates, and correlates the sampled values to gene expression values.</p>

<p>You can also look at this <a href="https://github.com/AllenBrainAtlas/human-analysis-examples">sample Python code</a>. It uses numpy to correlate the gene expression values of all of the samples to each other for one donor. There is also some code for picking one probe per gene. It chooses the probe that is most correlated to the other probes for that gene.</p>

<p>For inspiration, consider reading this study that integrates imaging and gene expression data:</p>

<p>Mueller K, Sacher J, Arelin K, Holiga S, Kratzsch J, et al. <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3565188/">Overweight and obesity are associated with neuronal injury in the human cerebellum and hippocampus in young adults: a combined MRI, serum marker and gene expression study.</a> Transl Psychiatry 2: e200. doi:10.1038/tp.2012.121.</p>

<p>Good luck!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HBM Hackathon Announced!]]></title>
    <link href="http://ohbm-seattle.github.io/blog/2013/04/15/hbm-hackathon-announced/"/>
    <updated>2013-04-15T00:00:00-07:00</updated>
    <id>http://ohbm-seattle.github.io/blog/2013/04/15/hbm-hackathon-announced</id>
    <content type="html"><![CDATA[<p><img src="http://ohbm-seattle.github.io/images/HBM_Hackthon_logo_small.png" width="200" height="232" title="&#34;HBM Hackathon&#34;" alt="&#34;HBM Hackathon&#34;">
The OHBM 2013 Local Organizing Committee (LOC) announces the <strong>HBM Hackathon</strong>, a meeting-long analysis and resource building competition designed to accelerate the connection between open neuroscience and cloud computing.</p>

<!-- more -->


<h4>Background</h4>

<p>OHBM 2013 occurs in a city at the forefront of open neuroscience and information technology.  With support from the <a href="http://www.alleninstitute.org" title="Allen Institute for Brain Science">Allen Institute for Brain Science</a>, <a href="http://aws.amazon.com" title="Amazon Web Services">Amazon Web Services</a>, and numerous other contributors, the 2013 meeting in Seattle will include an integrated hack room and associated cloud-computing contest called the <strong>HBM Hackathon</strong>. The hackathon will include a venue on the main poster/exhibit floor space, and prepared cloud-accessible data and software. These resources will be available to participants beginning two months ahead of the meeting, with in-kind support from Amazon Web Services in the form of <strong>$100 in cloud computing credits</strong> that will be made available to all registered HBM Hackathon participants attending OHBM 2013.</p>

<h4>HBM Hackathon Information</h4>

<ul>
<li><strong><a href="http://humanbrainmapping.org/hackathon">Registration</a></strong></li>
<li><strong><a href="http://ohbm-seattle.github.io/">Website and Blog</a></strong></li>
<li><strong><a href="http://www.linkedin.com/groups/HBM-Hackathon-4957800">Discussion Group</a></strong></li>
</ul>


<h4>Sponsors</h4>

<p>HBM Hackathon <em>major sponsors</em> include the Allen Institute for Brain Science and Amazon Web Services.</p>

<p>There are a number of <em>secondary sponsors</em> including:</p>

<ul>
<li>NITRC - <a href="http://www.nitrc.org" title="NITRC">Neuroimaging Informatics Tools and Resources Clearinghouse</a></li>
<li>IBIC - <a href="http://www.ibic.washington.edu" title="IBIC">University of Washington Integrated Brain Imaging Center</a></li>
<li>INCF - <a href="http://www.incf.org" title="INCF">International Neuroinformatics Coordinating Facility</a></li>
<li>BIRN - <a href="http://www.birncommunity.org" title="BIRN">Biomedical Informatics Research Network</a></li>
<li>NDAR - <a href="http://ndar.nih.gov" title="NDAR">National Database for Autism Research</a></li>
<li>LONI - <a href="http://www.loni.ucla.edu" title="LONI">Laboratory of NeuroImaging</a></li>
<li>HCP - <a href="http://www.humanconnectome.org" title="Human Connectome Project">Human Connectome Project</a></li>
<li><a href="http://www.frontiersin.org/Brain_Imaging_Methods" title="Frontiers in Brain Imaging Methods">Frontiers in Brain Imaging Methods</a></li>
<li>NIPY - <a href="http://nipy.sourceforge.net" title="NIPY">Neuroimaging in Python</a></li>
<li><a href="http://neuro.debian.net" title="NeuroDebian">NeuroDebian</a></li>
<li><a href="http://github.com" title="GitHub">GitHub</a></li>
</ul>


<p><em>Major sponsors</em> made donations specifically to support the HBM Hackathon program.</p>

<p><em>Secondary sponsors</em> are qualified by making tools and resources AWS-accessible in advance of the meeting, having an on-site presence (flagged consultation table in the Hack Room) during scheduled informal hack time during lunch and poster sessions and/or contributing relevant resources in support of the HBM Hackathon.</p>

<h4>Have an open human brain mapping resource you would like to have included?</h4>

<p>Just contact us: <a href="&#109;&#x61;&#105;&#x6c;&#116;&#x6f;&#58;&#104;&#98;&#x6d;&#46;&#x68;&#x61;&#99;&#107;&#97;&#116;&#104;&#111;&#x6e;&#x40;&#103;&#x6d;&#x61;&#x69;&#108;&#46;&#x63;&#111;&#109;">&#x68;&#98;&#x6d;&#x2e;&#104;&#97;&#x63;&#107;&#97;&#x74;&#104;&#x6f;&#110;&#x40;&#x67;&#x6d;&#x61;&#x69;&#x6c;&#x2e;&#x63;&#111;&#109;</a></p>

<h4>Venue</h4>

<p>OHBM has allocated approximately 3000 square feet of space on the poster/exhibit hall for a <em>Hack Room</em> that will include a podium and presentation equipment. The <em>Hack Room</em> will be used for collaboration as well as formal presentations accommodating up to 300 people. Sponsoring and contributing groups will be present to provide ongoing consultation and assistance with their respective resources, and may optionally make brief presentations at the podium.</p>

<h4>Schedule</h4>

<p>The HBM Hackathon program will take place during the lunch hour and poster sessions, and includes the Tuesday evening poster reception.</p>

<p><strong>Monday</strong> – sponsored by Allen Institute for Brain Science</p>

<blockquote><p><strong>12:30-1:30pm:</strong> HBM Hackathon orientation presentations.</p>

<ul>
<li>Shared Allen Institute and AWS presentations</li>
<li>Light box lunch</li>
</ul>


<p><strong>1:30-3:30pm:</strong> Informal hack activity</p>

<ul>
<li>Grassroots responses to contest challenges</li>
<li>Consultation/assistance from sponsoring groups</li>
<li>Brief presentations at north wall by participants/sponsors</li>
<li>Circulating contest judges</li>
</ul>
</blockquote>

<p><strong>Tuesday</strong> – sponsored by Amazon Web Services</p>

<blockquote><p><strong>12:30-3:30pm:</strong>  Informal hack activity as described under Monday (see above)</p>

<p><strong>6:00-7:30pm:</strong> Shared Allen Institute and AWS presentations</p></blockquote>

<p><strong>Wednesday</strong> – sponsor TBD</p>

<blockquote><p><strong>12:30-3:30pm:</strong> Informal hack activity as described under Monday (see above)</p>

<p><strong>1:30-3:00pm:</strong> Preliminary pitches to judges (see Judging below)</p></blockquote>

<p><strong>Thursday</strong> – sponsor TBD</p>

<blockquote><p><strong>10:45-12:15pm:</strong> Informal activity as described under Monday (see above)</p>

<p><strong>12:15-1:15pm:</strong> Final presentations and community voting</p>

<p><strong>1:15-1:45pm:</strong> HBM Hackathon reception</p></blockquote>

<h4>Contest and Challenges</h4>

<p>The contest will be organized around three Challenges, two of them pre-announced and open to work in advance of the meeting; and one announced at the time of the meeting. A brief overview of the challenges are provided here and a more detailed post will be provided separately as a post here at the <a href="http://ohbm-seattle.github.io">HBM Hackathon Blog</a>.</p>

<p>HBM Hackathon participants are encouraged to work in teams and will receive several incentives:</p>

<ul>
<li>$100 in cloud-computing credits per participant registered for OHBM</li>
<li>Private GitHub Repository for groups of five or more (50 total)</li>
</ul>


<p><strong>Challenge 1.</strong> Best imaging and gene expression relationship discovered via integration of imaging data with the Allen Human Brain Atlas.</p>

<blockquote><p>Here is a published example that would be responsive to this challenge:  Mathias Schroeter from Max Planck Institute will also be one of the speakers at the Imaging-Gene Expression Symposia during OHBM to talk about this paper.</p>

<p>Mueller K, Sacher J, Arelin K, Holiga S, Kratzsch J, et al. Overweight and obesity are associated with neuronal injury in the human cerebellum and hippocampus in young adults: a combined MRI, serum marker and gene expression study. Transl Psychiatry 2: e200. doi:10.1038/tp.2012.121.</p></blockquote>

<p><strong>Challenge 2.</strong> Best neural systems model or visualization based on large-scale integration of resting state fMRI data with other HBM Hackathon accessible datasets.</p>

<blockquote><p>Here is a published example that would be responsive to this challenge:</p>

<p>Uddin LQ, Supekar K, Amin H, Rykhlevskaia E, Nguyen DA, Greicius MD, Menon V. Dissociable connectivity within human angular gyrus and intraparietal sulcus: evidence from functional and structural connectivity. Cereb Cortex. 2010 20:2636-46.</p></blockquote>

<p><strong>Challenge 3.</strong> To be announced the week of the meeting. This &#8220;mystery&#8221; challenge is to be addressed entirely during the meeting using resources made openly available to the brain mapping community.</p>

<p><strong>Rules</strong></p>

<ul>
<li>Participants must use publicly available data that is listed on the HBM Hackathon Blog. If a public dataset is not listed that you want to use, we would love to add it to the list, just contact us: <a href="&#109;&#x61;&#x69;&#108;&#116;&#111;&#58;&#104;&#98;&#x6d;&#x2e;&#x68;&#x61;&#x63;&#107;&#x61;&#116;&#104;&#x6f;&#x6e;&#64;&#x67;&#109;&#x61;&#105;&#108;&#x2e;&#99;&#x6f;&#x6d;">&#104;&#x62;&#x6d;&#x2e;&#x68;&#x61;&#99;&#107;&#x61;&#116;&#x68;&#111;&#x6e;&#64;&#103;&#109;&#x61;&#105;&#108;&#x2e;&#x63;&#111;&#109;</a></li>
<li>Participants can use any computational resources available to them, but judging will take into account innovative use of cloud computing and how openly available the approach is (see Judging)</li>
<li>At least one team leader/presenter must attend the meeting</li>
<li>Off-site team members are allowed and encouraged, but will not be eligible for all resources made available to registered OHBM attendees (e.g., cloud computing credits)</li>
</ul>


<p><strong>Not interested in the challenges?</strong></p>

<p>Cooperative “hackathon” activity outside of the contest is also encouraged. Please feel free to visit the OHBM Hack Room during the meeting to learn about brain mapping community resources and/or work on a project like:</p>

<ol>
<li>Efforts that encourage data sharing and reproducible data processing</li>
<li>Dynamically configurable virtual machines (e.g. Amazon Machine Images)</li>
<li>Cloud-accessible 3D model library and other standard space atlas resources</li>
</ol>


<h4>Judging</h4>

<p>Participants will be judged using a combination of panel judging and peer voting. A committee of three judges not involved in the organization of the HBM Hackathon will be recruited.</p>

<p><strong>The responsibilities of the judges are to:</strong></p>

<ul>
<li>Circulate in the Hack Room during informal activity time, and consider self-nominated projects for inclusion in the preliminary judging session scheduled for Wednesday evening.</li>
<li>Attend the preliminary pitches of hack projects Wednesday 1:30-3:00pm at the north wall presentation space, and decide on 2-3 finalists in each category.</li>
</ul>


<p><strong>Criteria to be applied include:</strong></p>

<ul>
<li>Scientific impact</li>
<li>Innovative use of cloud services</li>
<li>Open availability of brain mapping tools, atlases, or datasets</li>
<li>Extent and diversity of data used</li>
</ul>


<p><strong>Preliminary judging session:</strong> Wednesday 1:30-3:00pm</p>

<ul>
<li>Judge-nominated projects pitch for 4 minute (5 slides) with one minute for questions</li>
<li>A maximum of 15 projects will be presented in this session</li>
<li>Judges select 2 per Challenge for final session on Thursday</li>
<li>Finalists may “pour it on” overnight</li>
</ul>


<p><strong>Final Presentations:</strong> Thursday 12:15-1:15pm</p>

<ul>
<li>Final projects present for 10 min total (including any questions)</li>
<li>Winners selected by community voting (i.e., of those attending)</li>
</ul>


<p><strong>Reception</strong> – Thursday 1:15-1:45pm</p>

<ul>
<li>Votes will be tabulated and winners will be announced</li>
<li>Refreshments will be provided</li>
</ul>


<h4>Prizes</h4>

<p>Winning entries in each category receive:</p>

<ul>
<li>An invitation to submit project to Frontiers in Brain Imaging Methods with Open Access Publication Fees waived (must undergo standard peer review)</li>
<li>Amazon Kindle Fire and/or Paperwhite (limit 3 per team)</li>
<li>AWS hosts AMI and/or data resulting from the hackathon free of charge</li>
<li>Free GitHub Membership with private repositories (Challenge 1: one year silver, Challenge 2: 1 year bronze, Challenge 3: six months bronze)</li>
</ul>


<h4>Thank you and good luck!</h4>

<p><strong>The HBM Hackathon Organizers</strong></p>

<ul>
<li>Thomas Grabowski, University of Washington, LOC Chair</li>
<li>Nolan Nichols, University of Washington</li>
<li>Chinh Dang, Allen Institute for Brain Science</li>
<li>Elaine Shen, Allen Institute for Brain Science</li>
<li>Rachel Pizarro, Amazon Web Services</li>
<li>Jamie Kinney, Amazon Web Services</li>
<li>Satrajit Ghosh, Massachusetts Institute of Technology</li>
<li>OHBM 2013 Local Organizing Committee</li>
</ul>

]]></content>
  </entry>
  
</feed>
